<!DOCTYPE html>
<html lang="ko" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Viterbi in HMM-GMM | macsim&#39;s Blog</title>
<meta name="keywords" content="">
<meta name="description" content="about Viterbi">
<meta name="author" content="macsim">
<link rel="canonical" href="http://localhost:1313/posts/tech/asr/viterbi/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.css" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.js" onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="http://localhost:1313/img/Q.gif">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/img/Q.gif">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/img/Q.gif">
<link rel="apple-touch-icon" href="http://localhost:1313/img/Q.gif">
<link rel="mask-icon" href="http://localhost:1313/img/Q.gif">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="ko" href="http://localhost:1313/posts/tech/asr/viterbi/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript>
<script defer src="https://unpkg.com/mermaid@8.8.1/dist/mermaid.min.js"></script>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css">
<script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.3/dist/jquery.min.js"></script>



<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = ""; 
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>

  

<meta property="og:title" content="Viterbi in HMM-GMM" />
<meta property="og:description" content="about Viterbi" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://localhost:1313/posts/tech/asr/viterbi/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2025-03-15T01:17:26+09:00" />
<meta property="article:modified_time" content="2025-03-15T01:17:26+09:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Viterbi in HMM-GMM"/>
<meta name="twitter:description" content="about Viterbi"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [

        {
          "@type": "ListItem",
          "position":  1 ,
          "name": "posts",
          "item": "http://localhost:1313/posts/"
        },

        {
          "@type": "ListItem",
          "position":  2 ,
          "name": "👨🏻‍💻 tech",
          "item": "http://localhost:1313/posts/tech/"
        }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "Viterbi in HMM-GMM",
      "item": "http://localhost:1313/posts/tech/asr/viterbi/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Viterbi in HMM-GMM",
  "name": "Viterbi in HMM-GMM",
  "description": "about Viterbi",
  "keywords": [
    ""
  ],
  "articleBody": "Viterbi 알고리즘의 기본 원리 Viterbi 알고리즘은 HMM(Hidden Markov Model)에서 가장 확률이 높은 은닉 상태 시퀀스를 찾기 위한 동적 프로그래밍 알고리즘이다. ASR에서는 관측된 음향 특징(acoustic features)이 주어졌을 때, 가장 확률이 높은 단어나 음소 시퀀스를 찾는 데 사용된다.\nViterbi 알고리즘의 주요 구성요소 상태 공간: HMM의 가능한 모든 상태들 ($S = {s_1, s_2, …, s_N}$) 관측 시퀀스: 시간에 따른 음향 특징 벡터 ($O = o_1, o_2, …, o_T$) 상태 전이 확률: 한 상태에서 다른 상태로 전이할 확률 ($a_{ij}$) 방출 확률: 특정 상태에서 관측값을 생성할 확률 ($b_j(o_t)$) Viterbi 알고리즘의 수식 초기화: $\\delta_1(i) = \\pi_i \\cdot b_i(o_1)$, $1 \\leq i \\leq N$ $$\\psi_1(i) = 0$$ 여기서 $\\pi_i$는 상태 $i$의 초기 확률, $\\delta_t(i)$는 시간 $t$에서 상태 $i$에 도달하는 최대 확률 경로의 확률이다.\n재귀: $$\\delta_t(j) = \\max_{1 \\leq i \\leq N} [\\delta_{t-1}(i) \\cdot a_{ij}] \\cdot b_j(o_t)$$ $$2 \\leq t \\leq T, 1 \\leq j \\leq N$$\n$$\\psi_t(j) = \\arg\\max_{1 \\leq i \\leq N} [\\delta_{t-1}(i) \\cdot a_{ij}]$$\n종료: $$P^* = \\max_{1 \\leq i \\leq N} [\\delta_T(i)]$$ $$q_T^* = \\arg\\max_{1 \\leq i \\leq N} [\\delta_T(i)]$$\n경로 역추적: $$q_t^* = \\psi_{t+1}(q_{t+1}^*), t = T-1, T-2, …, 1$$\nViterbi의 구체적 예시 무슨 말인지 모르겠다면 예시를 통해 좀 더 쉽게 이해할 수 있다. 음성 인식에서 “나는” 이라는 단어를 인식하는 간단한 예를 통해 Viterbi 알고리즘을 알아보자.\n문제 설정: 인식할 단어: “나는” 음소 분해: /ㄴ/, /ㅏ/, /ㄴ/, /ㅡ/, /ㄴ/ 각 음소는 3개의 상태를 가진 HMM으로 모델링 (시작, 중간, 끝) 관측 시퀀스: 5개의 음향 특징 벡터 $O = {o_1, o_2, o_3, o_4, o_5}$ HMM 파라미터: 상태 집합: /ㄴ1/, /ㄴ2/, /ㄴ3/, /ㅏ1/, /ㅏ2/, /ㅏ3/, /ㄴ1’/, /ㄴ2’/, /ㄴ3’/, /ㅡ1/, /ㅡ2/, /ㅡ3/, /ㄴ1’’/, /ㄴ2’’/, /ㄴ3’’/ (총 15개 상태) 전이 확률 (일부 예시): $$a_{/ㄴ1/, /ㄴ2/} = 0.7$$ (첫 /ㄴ/의 첫 상태에서 두 번째 상태로) $$a_{/ㄴ2/, /ㄴ3/} = 0.8$$ $$a_{/ㄴ3/, /ㅏ1/} = 0.9$$ (첫 /ㄴ/의 끝 상태에서 /ㅏ/의 첫 상태로)\n방출 확률 (t=1 시점의 예시): $$b_{/ㄴ1/}(o_1) = 0.4$$ $$b_{/ㅏ1/}(o_1) = 0.1$$ $$b_{/ㅡ1/}(o_1) = 0.05$$\nViterbi 알고리즘 실행: 초기화 (t=1): $$\\delta_1(/ㄴ1/) = \\pi_{/ㄴ1/} \\cdot b_{/ㄴ1/}(o_1) = 1.0 \\times 0.4 = 0.4$$ (첫 음소의 첫 상태로 시작한다고 가정) 다른 모든 상태의 초기 확률은 0\nt=2 계산: $$\\delta_2(/ㄴ2/) = \\delta_1(/ㄴ1/) \\cdot a_{/ㄴ1/, /ㄴ2/} \\cdot b_{/ㄴ2/}(o_2)$$ $$= 0.4 \\times 0.7 \\times 0.3 = 0.084$$ $$\\delta_2(/ㄴ1/) = \\delta_1(/ㄴ1/) \\cdot a_{/ㄴ1/, /ㄴ1/} \\cdot b_{/ㄴ1/}(o_2)$$ $$= 0.4 \\times 0.2 \\times 0.25 = 0.02$$\nt=3 계산: $$\\delta_3(/ㄴ3/) = \\delta_2(/ㄴ2/) \\cdot a_{/ㄴ2/, /ㄴ3/} \\cdot b_{/ㄴ3/}(o_3)$$ $$= 0.084 \\times 0.8 \\times 0.5 = 0.0336$$ $$\\delta_3(/ㄴ2/) = \\max[\\delta_2(/ㄴ1/) \\cdot a_{/ㄴ1/, /ㄴ2/}, \\delta_2(/ㄴ2/) \\cdot a_{/ㄴ2/, /ㄴ2/}] \\cdot b_{/ㄴ2/}(o_3)$$ $$= \\max[0.02 \\times 0.7, 0.084 \\times 0.1] \\times 0.45$$ $$= \\max[0.014, 0.0084] \\times 0.45 = 0.014 \\times 0.45 = 0.0063$$\n계속해서 t=4, t=5까지 계산:\n마찬가지 방식으로 모든 가능한 상태 전이에 대해 확률을 계산한다.\n최종 결과:\n가정된 값들로 계산을 완료하면, 가장 높은 확률을 가진 상태 시퀀스: /ㄴ1/ → /ㄴ2/ → /ㄴ3/ → /ㅏ1/ → /ㅏ2/ → /ㅏ3/ → /ㄴ1’/ → …\n방출 확률($b_j(o_t)$), 상태 전이 확률($a_{ij}$) 그렇다면 대체 ‘방출 확률($b_j(o_t)$)‘과 ‘상태 전이 확률($a_{ij}$)’ 이라는 것은 어떻게 구할까?!\n상태 전이 확률($a_{ij}$) 구하기 전문가 지식 기반 초기화 사용 시점: 모델 학습 시작 전 초기값 설정\n3-상태 left-to-right HMM 구조에서: 자기 루프(self-loop): $a_{ii} \\approx 0.6$ 다음 상태로 전이: $a_{i,i+1} \\approx 0.4$ Kaldi의 topo 파일에 이러한 초기값 정의 Baum-Welch 알고리즘 (EM 기반) 사용 시점: 모델 학습 과정\nBaum-Welch 알고리즘 (EM 알고리즘의 HMM 버전) E(Expectation)-단계: 전방($\\alpha$)/후방($\\beta$) 확률 계산 통계 수집: $\\xi_t(i,j)$ (시간 $t$에 상태 $i$, 시간 $t+1$에 상태 $j$에 있을 확률) M(Maximization)-단계: 상태 전이 확률 업데이트 $$a_{ij} = \\frac{\\sum_{t=1}^{T-1} \\xi_t(i,j)}{\\sum_{t=1}^{T-1} \\gamma_t(i)}$$ 여기서:\n$\\xi_t(i,j)$: 시간 $t$에 상태 $i$, 시간 $t+1$에 상태 $j$에 있을 확률\n$\\gamma_t(i)$: 시간 $t$에 상태 $i$에 있을 확률\n강제 정렬(Forced Alignment) 기반 사용 시점: 모델 세련화 및 정제 단계\n음성-텍스트 쌍이 있는 학습 데이터 준비 현재 모델로 발화를 알려진 텍스트와 강제 정렬 상태 시퀀스를 카운트하여 전이 확률 계산(카운트를 정규화하여 확률 계산): $$a_{ij} = \\frac{카운트(상태 i에서 j로 전이)}{카운트(상태 i에서의 모든 전이)}$$ 방출 확률($b_j(o_t)$) 구하기 GMM은 여러 가우시안 분포의 가중 합으로 표현되는 확률 밀도 함수다. HMM-GMM 시스템에서는 각 HMM 상태의 방출 확률을 GMM으로 모델링한다:\n각 HMM 상태 $j$의 방출 확률은 가우시안 혼합 모델로 표현:\n$b_j(o_t) = \\sum_{m=1}^M c_{jm} \\mathcal{N}(o_t; \\mu_{jm}, \\Sigma_{jm})$\n$c_{jm}$: $m$번째 가우시안 컴포넌트의 가중치 (모든 가중치 합은 1)\n$\\mu_{jm}$: $m$번째 가우시안의 평균 벡터\n$\\Sigma_{jm}$: $m$번째 가우시안의 공분산 행렬\n$\\mathcal{N}(o_t; \\mu, \\Sigma)$: 평균 $\\mu$, 공분산 $\\Sigma$를 가진 다변량 가우시안 밀도 함수\n(나중에 따로 GMM에 대해서 포스팅을 하든지 해야겠다. 이 수식만 봐서는 어떻게 구할 수 있는 것인지 감이 안 잡힌다. 다만 아래 학습 과정으로 이루어 지는 것을 알고 넘어가자)\n방출 확률 학습방법 GMM 초기화 사용 시점: 모델 학습 시작 전\n방법:\n각 상태에 할당된 특징 벡터의 k-means 클러스터링 초기 GMM 컴포넌트 생성 (평균, 공분산, 가중치) Kaldi에서는 gmm-init-mono 등의 명령어로 구현 Baum-Welch 알고리즘 내 GMM 업데이트 사용 시점: 모델 학습 과정\n방법:\nE-단계에서 각 프레임의 상태 소속 확률 $\\gamma_t(j)$ 계산 각 가우시안 컴포넌트에 대한 책임 확률($\\gamma_t(j,m)$) 계산: $$\\gamma_t(j,m) = \\gamma_t(j) \\cdot \\frac{c_{jm} \\mathcal{N}(o_t; \\mu_{jm}, \\Sigma_{jm})}{\\sum_{k=1}^M c_{jk} \\mathcal{N}(o_t; \\mu_{jk}, \\Sigma_{jk})}$$ GMM 파라미터 업데이트:\n가중치: $c_{jm} = \\frac{\\sum_{t=1}^T \\gamma_t(j,m)}{\\sum_{t=1}^T \\gamma_t(j)}$\n평균: $\\mu_{jm} = \\frac{\\sum_{t=1}^T \\gamma_t(j,m) \\cdot o_t}{\\sum_{t=1}^T \\gamma_t(j,m)}$\n공분산: $\\Sigma_{jm} = \\frac{\\sum_{t=1}^T \\gamma_t(j,m) \\cdot (o_t - \\mu_{jm})(o_t - \\mu_{jm})^T}{\\sum_{t=1}^T \\gamma_t(j,m)}$\n정렬 기반 GMM 세련화 사용 시점: 모델 세련화 단계\n방법:\n강제 정렬로 특징 벡터를 HMM 상태에 할당 정렬된 데이터로 더 복잡한 GMM 학습 (예: 혼합 수 증가) Kaldi에서는 gmm-acc-stats-ali와 gmm-est로 구현 책임 확률 수식 $$\\gamma_t(j,m) = \\gamma_t(j) \\cdot \\frac{c_{jm} \\mathcal{N}(o_t; \\mu_{jm}, \\Sigma_{jm})}{\\sum_{k=1}^M c_{jk} \\mathcal{N}(o_t; \\mu_{jk}, \\Sigma_{jk})}$$ 이 수식은 상태 $j$의 $m$번째 가우시안 컴포넌트가 관측값 $o_t$를 생성할 책임(responsibility) 을 나타낸다. 즉, 관측값 $o_t$가 상태 $j$에서 생성되었다는 조건하에, 그 중에서도 $m$번째 가우시안 컴포넌트에서 생성되었을 확률이다.\n방출 확률 수식 $$b_j(o_t) = \\sum_{m=1}^M c_{jm} \\mathcal{N}(o_t; \\mu_{jm}, \\Sigma_{jm})$$ 이 수식은 상태 $j$에서 관측값 $o_t$를 생성할 방출 확률(emission probability) 을 나타낸다. GMM으로 모델링된 확률 밀도 함수이다.\n두 수식의 관계 중요한 점은 첫 번째 수식의 분모가 바로 두 번째 수식과 같다는 것이다:\n$$\\sum_{k=1}^M c_{jk} \\mathcal{N}(o_t; \\mu_{jk}, \\Sigma_{jk}) = b_j(o_t)$$ 따라서 첫 번째 수식은 다음과 같이 다시 쓸 수 있다:\n$$\\gamma_t(j,m) = \\gamma_t(j) \\cdot \\frac{c_{jm} \\mathcal{N}(o_t; \\mu_{jm}, \\Sigma_{jm})}{b_j(o_t)}$$ 이는 Baum-Welch 알고리즘의 E-단계에서 계산되는 값으로:\n$\\gamma_t(j)$: 시간 $t$에 상태 $j$에 있을 확률\n$\\frac{c_{jm} \\mathcal{N}(o_t; \\mu_{jm}, \\Sigma_{jm})}{b_j(o_t)}$: 상태 $j$ 내에서 $m$번째 가우시안 컴포넌트의 기여도 두 수식은 다른 의미를 가지지만, GMM 파라미터 학습 과정에서 서로 연관되어 사용된다:\n방출 확률 $b_j(o_t)$는 HMM의 기본 구성요소 책임 확률 $\\gamma_t(j,m)$은 GMM 파라미터 업데이트에 사용되는 통계량 DNN-HMM 하이브리드 시스템에서 DNN의 GMM 대체 방식 기본 개념의 변화 GMM-HMM 시스템에서 DNN-HMM 하이브리드 시스템으로의 전환은 ASR 발전에 있어 중요한 패러다임 변화였다. 주요 변화는 다음과 같다\nGMM-HMM에서\nGMM은 생성 모델(generative model)로 $p(o_t|s_j)$, 즉 상태 $j$가 주어졌을 때 관측값 $o_t$의 우도(likelihood)를 직접 모델링\n각 HMM 상태마다 별도의 GMM이 존재\n방출 확률: $b_j(o_t) = p(o_t|s_j) = \\sum_{m=1}^M c_{jm} \\mathcal{N}(o_t; \\mu_{jm}, \\Sigma_{jm})$\nDNN-HMM에서:\nDNN은 판별 모델(discriminative model)로 $p(s_j|o_t)$, 즉 관측값 $o_t$가 주어졌을 때 상태 $j$의 사후 확률(posterior)을 예측\n하나의 DNN이 모든 상태의 사후 확률을 동시에 출력\n베이즈 규칙으로 우도로 변환: $p(o_t|s_j) \\propto \\frac{p(s_j|o_t)}{p(s_j)}$\nDNN이 GMM을 대체하는 메커니즘 DNN은 다음과 같은 방식으로 GMM의 역할을 대체한다:\n입력: 음향 특징(MFCC, FBANK 등)과 그 문맥(앞뒤 프레임)\n출력: 각 HMM 상태(senone)에 대한 사후 확률\n디코딩 시 사용: 베이즈 규칙을 통해 우도로 변환\nGMM-HMM으로 초기 강제 정렬 수행 정렬된 프레임 레이블을 사용해 DNN 학습 (교차 엔트로피 손실 함수)\n출력층은 softmax 활성화 함수를 통해 모든 HMM 상태에 대한 확률 출력\n디코딩 단계 DNN이 각 프레임에 대한 상태 사후 확률 $p(s_j|o_t)$ 출력\n사후 확률을 우도로 변환: $p(o_t|s_j) \\propto \\frac{p(s_j|o_t)}{p(s_j)}$\n이 우도를 HMM 디코더에 제공 (Viterbi, Beam Search 등)\n여기서 $p(s_j)$는 상태의 사전 확률로, 학습 데이터에서 각 상태의 출현 빈도를 계산하여 얻는다.\n주요 혁신 포인트 특징 표현력 GMM: 확률 분포를 명시적으로 모델링하지만 복잡한 패턴 인식에 제한적\nDNN: 비선형 변환을 통해 더 복잡한 패턴 인식 가능, 더 강력한 특징 표현 학습\n문맥 정보 활용 GMM: 주로 현재 프레임의 특징만 사용\nDNN: 여러 프레임을 입력으로 받아 더 긴 문맥 정보 활용 가능 (예: 9프레임 윈도우)\n파라미터 공유 GMM: 각 상태마다 별도의 파라미터 집합\nDNN: 하나의 네트워크로 모든 상태의 확률 계산, 하위 층에서 특징 표현 공유\n",
  "wordCount" : "3778",
  "inLanguage": "ko",
  "datePublished": "2025-03-15T01:17:26+09:00",
  "dateModified": "2025-03-15T01:17:26+09:00",
  "author":[{
    "@type": "Person",
    "name": "macsim"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://localhost:1313/posts/tech/asr/viterbi/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "macsim's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "http://localhost:1313/img/Q.gif"
    }
  }
}
</script>
</head>

<body class=" dark" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="Macsim&#39;s Blog (Alt + H)">Macsim&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                         fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                         stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                         fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                         stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                </ul>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/" title="🏠 home">
                <span>🏠 home</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/about/" title="🙋 about">
                <span>🙋 about</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/archives/" title="archives">
                <span>archives</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/posts/" title="📚 posts">
                <span>📚 posts</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/tags/" title="🧩 tags">
                <span>🧩 tags</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/search/" title="⏱️ search (Alt &#43; /)" accesskey=/>
                <span>⏱️ search</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main page">
<style>
    i[id*="post_meta_style"] {
        display: flex;
        align-items: center;
        margin: 0 0 10px 0;
    }
</style>

<article class="post-single">
    <div id="single-content">
        <header class="post-header">
            <div class="breadcrumbs"><a href="http://localhost:1313/">🏠 홈</a>&nbsp;»&nbsp;<a href="http://localhost:1313/posts/">posts</a>&nbsp;»&nbsp;<a href="http://localhost:1313/posts/tech/">👨🏻‍💻 tech</a></div>
            <h1 class="post-title">
                Viterbi in HMM-GMM<sup><span class="entry-isdraft">&nbsp;&nbsp;[draft]</span></sup>
            </h1>
            <div class="post-description">
                about Viterbi
            </div>
            <div class="post-meta">

<style>
    i[id*="post_meta_style"] {
        display: flex;
        align-items: center;
        margin: 0 0 10px 0;
    }

    .parent-post-meta {
        display: flex;
        flex-wrap: wrap;
        opacity: 0.8;
    }
</style>

<span class="parent-post-meta">
    <span id="post_meta_style_1">
        <span class="fa fa-calendar-check-o"></span>
        <span>2025-03-15
            &nbsp;&nbsp;
        </span>
    </span>
    
    
    
    
    
    
    
    <span id="post_meta_style_3">
        <span class="fa fa-file-word-o"></span>
        <span>3778 word
            &nbsp;&nbsp;
        </span>
    </span>
    <span id="post_meta_style_4">
        <span class="fa fa-clock-o"></span>
        <span>8 min
            &nbsp;&nbsp;
        </span>
    </span>
    <span id="post_meta_style_5">
        <span class="fa fa-user-o"></span>
        <span>macsim
            &nbsp;&nbsp;
        </span>
    </span>
    <span id="post_meta_style_6">
        <span class="fa fa-tags" style="opacity: 0.8"></span>
        <span>
            <span class="post-tags-meta">
                <a href="http://localhost:1313/tags/asr/" style="color: var(--secondary)!important;">ASR</a>
                &nbsp;<a href="http://localhost:1313/tags/viterbi/" style="color: var(--secondary)!important;">Viterbi</a>
                &nbsp;<a href="http://localhost:1313/tags/hmm-gmm/" style="color: var(--secondary)!important;">HMM-GMM</a>
            </span>
        </span>
    </span>
</span>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css" integrity="sha384-nB0miv6/jRmo5UMMR1wu3Gz6NLsoTkbqJghGIsx//Rlm+ZU03BU6SQNC66uf4l5+" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js" integrity="sha384-7zkQWkzuo3B5mTepMUcHkMB5jZaolc2xDwL6VFqjFALcbeS9Ggm/Yr2r3Dy4lfFg" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js" integrity="sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk" crossorigin="anonymous"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          
          
          delimiters: [
              {left: '$$', right: '$$', display: true},
              {left: '$', right: '$', display: false},
              {left: '\\(', right: '\\)', display: false},
              {left: '\\[', right: '\\]', display: true}
          ],
          
          throwOnError : false
        });
    });
</script>

                <span style="opacity: 0.8;">
                    <span id="post_meta_style_7">
                        &nbsp;&nbsp;
                        <span class="fa fa-eye" ></span>
                        <span>
                            <span id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv"></span></span>
                            &nbsp;&nbsp;
                        </span>
                    </span>
                    <span id="post_meta_style_8">
                        <span class="fa fa-commenting-o"></span>
                        <span>
                            <script src="https://cdn.staticfile.org/twikoo/1.5.8/twikoo.all.min.js"></script>
                            <script>
                                let url = document.documentURI
                                
                                let dnsUrl = "http://localhost:1313/"
                                let urlSplit = url.split(dnsUrl)
                                let finalUrl = urlSplit[1]
                                if (finalUrl[0] !== '/') {
                                    finalUrl = '/'+finalUrl
                                }
                                twikoo.getCommentsCount({
                                    envId:  null , 
                                region:  null , 
                                urls: [ 
                                    
                                    finalUrl,
                                ],
                                    includeReply: false 
                                }).then(function (res) {
                                    let count = res[0].count
                                    const obj = document.getElementById("comment_count");
                                    obj.innerText = count
                                    
                                    
                                    
                                }).catch(function (err) {
                                    
                                    console.error(err);
                                });
                            </script>
                            <span id="comment_count"></span>
                        </span>
                    </span>
                </span>

</div>
        </header> <aside id="toc-container" class="toc-container wide">
    <div class="toc">
        <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">목차</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#viterbi-%ec%95%8c%ea%b3%a0%eb%a6%ac%ec%a6%98%ec%9d%98-%ea%b8%b0%eb%b3%b8-%ec%9b%90%eb%a6%ac" aria-label="Viterbi 알고리즘의 기본 원리">Viterbi 알고리즘의 기본 원리</a><ul>
                        
                <li>
                    <a href="#viterbi-%ec%95%8c%ea%b3%a0%eb%a6%ac%ec%a6%98%ec%9d%98-%ec%a3%bc%ec%9a%94-%ea%b5%ac%ec%84%b1%ec%9a%94%ec%86%8c" aria-label="Viterbi 알고리즘의 주요 구성요소">Viterbi 알고리즘의 주요 구성요소</a></li></ul>
                </li>
                <li>
                    <a href="#viterbi-%ec%95%8c%ea%b3%a0%eb%a6%ac%ec%a6%98%ec%9d%98-%ec%88%98%ec%8b%9d" aria-label="Viterbi 알고리즘의 수식">Viterbi 알고리즘의 수식</a></li>
                <li>
                    <a href="#viterbi%ec%9d%98-%ea%b5%ac%ec%b2%b4%ec%a0%81-%ec%98%88%ec%8b%9c" aria-label="Viterbi의 구체적 예시">Viterbi의 구체적 예시</a></li>
                <li>
                    <a href="#%eb%b0%a9%ec%b6%9c-%ed%99%95%eb%a5%a0b_jo_t-%ec%83%81%ed%83%9c-%ec%a0%84%ec%9d%b4-%ed%99%95%eb%a5%a0a_ij" aria-label="방출 확률($b_j(o_t)$), 상태 전이 확률($a_{ij}$)">방출 확률($b_j(o_t)$), 상태 전이 확률($a_{ij}$)</a><ul>
                        
                <li>
                    <a href="#%ec%83%81%ed%83%9c-%ec%a0%84%ec%9d%b4-%ed%99%95%eb%a5%a0a_ij-%ea%b5%ac%ed%95%98%ea%b8%b0" aria-label="상태 전이 확률($a_{ij}$) 구하기">상태 전이 확률($a_{ij}$) 구하기</a></li>
                <li>
                    <a href="#%eb%b0%a9%ec%b6%9c-%ed%99%95%eb%a5%a0b_jo_t-%ea%b5%ac%ed%95%98%ea%b8%b0" aria-label="방출 확률($b_j(o_t)$) 구하기">방출 확률($b_j(o_t)$) 구하기</a><ul>
                        
                <li>
                    <a href="#%eb%b0%a9%ec%b6%9c-%ed%99%95%eb%a5%a0-%ed%95%99%ec%8a%b5%eb%b0%a9%eb%b2%95" aria-label="방출 확률 학습방법">방출 확률 학습방법</a></li>
                <li>
                    <a href="#%ec%b1%85%ec%9e%84-%ed%99%95%eb%a5%a0-%ec%88%98%ec%8b%9d" aria-label="책임 확률 수식">책임 확률 수식</a></li>
                <li>
                    <a href="#%eb%b0%a9%ec%b6%9c-%ed%99%95%eb%a5%a0-%ec%88%98%ec%8b%9d" aria-label="방출 확률 수식">방출 확률 수식</a></li>
                <li>
                    <a href="#%eb%91%90-%ec%88%98%ec%8b%9d%ec%9d%98-%ea%b4%80%ea%b3%84" aria-label="두 수식의 관계">두 수식의 관계</a></li></ul>
                </li></ul>
                </li>
                <li>
                    <a href="#dnn-hmm-%ed%95%98%ec%9d%b4%eb%b8%8c%eb%a6%ac%eb%93%9c-%ec%8b%9c%ec%8a%a4%ed%85%9c%ec%97%90%ec%84%9c-dnn%ec%9d%98-gmm-%eb%8c%80%ec%b2%b4-%eb%b0%a9%ec%8b%9d" aria-label="DNN-HMM 하이브리드 시스템에서 DNN의 GMM 대체 방식">DNN-HMM 하이브리드 시스템에서 DNN의 GMM 대체 방식</a><ul>
                        
                <li>
                    <a href="#%ea%b8%b0%eb%b3%b8-%ea%b0%9c%eb%85%90%ec%9d%98-%eb%b3%80%ed%99%94" aria-label="기본 개념의 변화">기본 개념의 변화</a></li>
                <li>
                    <a href="#dnn%ec%9d%b4-gmm%ec%9d%84-%eb%8c%80%ec%b2%b4%ed%95%98%eb%8a%94-%eb%a9%94%ec%bb%a4%eb%8b%88%ec%a6%98" aria-label="DNN이 GMM을 대체하는 메커니즘">DNN이 GMM을 대체하는 메커니즘</a><ul>
                        
                <li>
                    <a href="#gmm-hmm%ec%9c%bc%eb%a1%9c-%ec%b4%88%ea%b8%b0-%ea%b0%95%ec%a0%9c-%ec%a0%95%eb%a0%ac-%ec%88%98%ed%96%89" aria-label="GMM-HMM으로 초기 강제 정렬 수행">GMM-HMM으로 초기 강제 정렬 수행</a></li>
                <li>
                    <a href="#%eb%94%94%ec%bd%94%eb%94%a9-%eb%8b%a8%ea%b3%84" aria-label="디코딩 단계">디코딩 단계</a></li></ul>
                </li>
                <li>
                    <a href="#%ec%a3%bc%ec%9a%94-%ed%98%81%ec%8b%a0-%ed%8f%ac%ec%9d%b8%ed%8a%b8" aria-label="주요 혁신 포인트">주요 혁신 포인트</a>
                </li>
            </ul>
            </li>
            </ul>
        </div>
        </details>
    </div>
</aside>
<script>
    let activeElement;
    let elements;
    window.addEventListener('DOMContentLoaded', function (event) {
        checkTocPosition();

        elements = document.querySelectorAll('h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]');
        
        activeElement = elements[0];
        const id = encodeURI(activeElement.getAttribute('id')).toLowerCase();
        document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
    }, false);

    window.addEventListener('resize', function(event) {
        checkTocPosition();
    }, false);

    window.addEventListener('scroll', () => {
        
        if (elements) {
            activeElement = Array.from(elements).find((element) => {
                if ((getOffsetTop(element) - window.pageYOffset) > 0 &&
                    (getOffsetTop(element) - window.pageYOffset) < window.innerHeight/2) {
                    return element;
                }
            }) || activeElement

            elements.forEach(element => {
                const id = encodeURI(element.getAttribute('id')).toLowerCase();
                if (element === activeElement){
                    document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
                } else {
                    document.querySelector(`.inner ul li a[href="#${id}"]`).classList.remove('active');
                }
            })
        }
    }, false);

    const main = parseInt(getComputedStyle(document.body).getPropertyValue('--article-width'), 10);
    const toc = parseInt(getComputedStyle(document.body).getPropertyValue('--toc-width'), 10);
    const gap = parseInt(getComputedStyle(document.body).getPropertyValue('--gap'), 10);

    function checkTocPosition() {
        const width = document.body.scrollWidth;
        if (width - main - (toc * 2) - (gap * 4) > 0) {
            document.getElementById("toc-container").classList.add("wide");
        } else {
            document.getElementById("toc-container").classList.remove("wide");
        }
    }

    function getOffsetTop(element) {
        if (!element.getClientRects().length) {
            return 0;
        }
        let rect = element.getBoundingClientRect();
        let win = element.ownerDocument.defaultView;
        return rect.top + win.pageYOffset;
    }
</script>
        <div class="post-content"><h2 id="viterbi-알고리즘의-기본-원리">Viterbi 알고리즘의 기본 원리<a hidden class="anchor" aria-hidden="true" href="#viterbi-알고리즘의-기본-원리">#</a></h2>
<p>Viterbi 알고리즘은 HMM(Hidden Markov Model)에서 가장 확률이 높은 은닉 상태 시퀀스를 찾기 위한 동적 프로그래밍 알고리즘이다. ASR에서는 관측된 음향 특징(acoustic features)이 주어졌을 때, 가장 확률이 높은 단어나 음소 시퀀스를 찾는 데 사용된다.</p>
<h3 id="viterbi-알고리즘의-주요-구성요소">Viterbi 알고리즘의 주요 구성요소<a hidden class="anchor" aria-hidden="true" href="#viterbi-알고리즘의-주요-구성요소">#</a></h3>
<ol>
<li>상태 공간: HMM의 가능한 모든 상태들 ($S = {s_1, s_2, &hellip;, s_N}$)</li>
<li>관측 시퀀스: 시간에 따른 음향 특징 벡터 ($O = o_1, o_2, &hellip;, o_T$)</li>
<li>상태 전이 확률: 한 상태에서 다른 상태로 전이할 확률 ($a_{ij}$)</li>
<li>방출 확률: 특정 상태에서 관측값을 생성할 확률 ($b_j(o_t)$)</li>
</ol>
<h2 id="viterbi-알고리즘의-수식">Viterbi 알고리즘의 수식<a hidden class="anchor" aria-hidden="true" href="#viterbi-알고리즘의-수식">#</a></h2>
<ol>
<li>초기화:</li>
</ol>
<p>$\delta_1(i) = \pi_i \cdot b_i(o_1)$, $1 \leq i \leq N$
$$\psi_1(i) = 0$$
여기서 $\pi_i$는 상태 $i$의 초기 확률, $\delta_t(i)$는 시간 $t$에서 상태 $i$에 도달하는 최대 확률 경로의 확률이다.</p>
<ol start="2">
<li>재귀:</li>
</ol>
<p>$$\delta_t(j) = \max_{1 \leq i \leq N} [\delta_{t-1}(i) \cdot a_{ij}] \cdot b_j(o_t)$$ $$2 \leq t \leq T, 1 \leq j \leq N$$</p>
<p>$$\psi_t(j) = \arg\max_{1 \leq i \leq N} [\delta_{t-1}(i) \cdot a_{ij}]$$</p>
<ol start="3">
<li>종료:</li>
</ol>
<p>$$P^* = \max_{1 \leq i \leq N} [\delta_T(i)]$$
$$q_T^* = \arg\max_{1 \leq i \leq N} [\delta_T(i)]$$</p>
<ol start="4">
<li>경로 역추적:</li>
</ol>
<p>$$q_t^* = \psi_{t+1}(q_{t+1}^*), t = T-1, T-2, &hellip;, 1$$</p>
<h2 id="viterbi의-구체적-예시">Viterbi의 구체적 예시<a hidden class="anchor" aria-hidden="true" href="#viterbi의-구체적-예시">#</a></h2>
<p>무슨 말인지 모르겠다면 예시를 통해 좀 더 쉽게 이해할 수 있다.
음성 인식에서 &ldquo;나는&rdquo; 이라는 단어를 인식하는 간단한 예를 통해 Viterbi 알고리즘을 알아보자.</p>
<ol>
<li>문제 설정:
인식할 단어: &ldquo;나는&rdquo;
음소 분해: /ㄴ/, /ㅏ/, /ㄴ/, /ㅡ/, /ㄴ/
각 음소는 3개의 상태를 가진 HMM으로 모델링 (시작, 중간, 끝)
관측 시퀀스: 5개의 음향 특징 벡터 $O = {o_1, o_2, o_3, o_4, o_5}$</li>
<li>HMM 파라미터:
상태 집합:
/ㄴ1/, /ㄴ2/, /ㄴ3/, /ㅏ1/, /ㅏ2/, /ㅏ3/, /ㄴ1&rsquo;/, /ㄴ2&rsquo;/, /ㄴ3&rsquo;/, /ㅡ1/, /ㅡ2/, /ㅡ3/, /ㄴ1&rsquo;&rsquo;/, /ㄴ2&rsquo;&rsquo;/, /ㄴ3&rsquo;&rsquo;/ (총 15개 상태)</li>
</ol>
<p>전이 확률 (일부 예시):
$$a_{/ㄴ1/, /ㄴ2/} = 0.7$$ (첫 /ㄴ/의 첫 상태에서 두 번째 상태로)
$$a_{/ㄴ2/, /ㄴ3/} = 0.8$$
$$a_{/ㄴ3/, /ㅏ1/} = 0.9$$ (첫 /ㄴ/의 끝 상태에서 /ㅏ/의 첫 상태로)</p>
<p>방출 확률 (t=1 시점의 예시):
$$b_{/ㄴ1/}(o_1) = 0.4$$
$$b_{/ㅏ1/}(o_1) = 0.1$$
$$b_{/ㅡ1/}(o_1) = 0.05$$</p>
<ol start="3">
<li>Viterbi 알고리즘 실행:</li>
</ol>
<p>초기화 (t=1):
$$\delta_1(/ㄴ1/) = \pi_{/ㄴ1/} \cdot b_{/ㄴ1/}(o_1) = 1.0 \times 0.4 = 0.4$$
(첫 음소의 첫 상태로 시작한다고 가정)
다른 모든 상태의 초기 확률은 0</p>
<p>t=2 계산:
$$\delta_2(/ㄴ2/) = \delta_1(/ㄴ1/) \cdot a_{/ㄴ1/, /ㄴ2/} \cdot b_{/ㄴ2/}(o_2)$$
$$= 0.4 \times 0.7 \times 0.3 = 0.084$$
$$\delta_2(/ㄴ1/) = \delta_1(/ㄴ1/) \cdot a_{/ㄴ1/, /ㄴ1/} \cdot b_{/ㄴ1/}(o_2)$$
$$= 0.4 \times 0.2 \times 0.25 = 0.02$$</p>
<p>t=3 계산:
$$\delta_3(/ㄴ3/) = \delta_2(/ㄴ2/) \cdot a_{/ㄴ2/, /ㄴ3/} \cdot b_{/ㄴ3/}(o_3)$$
$$= 0.084 \times 0.8 \times 0.5 = 0.0336$$
$$\delta_3(/ㄴ2/) = \max[\delta_2(/ㄴ1/) \cdot a_{/ㄴ1/, /ㄴ2/}, \delta_2(/ㄴ2/) \cdot a_{/ㄴ2/, /ㄴ2/}] \cdot b_{/ㄴ2/}(o_3)$$
$$= \max[0.02 \times 0.7, 0.084 \times 0.1] \times 0.45$$
$$= \max[0.014, 0.0084] \times 0.45 = 0.014 \times 0.45 = 0.0063$$</p>
<p>계속해서 t=4, t=5까지 계산:<br>
마찬가지 방식으로 모든 가능한 상태 전이에 대해 확률을 계산한다.</p>
<p>최종 결과:<br>
가정된 값들로 계산을 완료하면, 가장 높은 확률을 가진 상태 시퀀스:
/ㄴ1/ → /ㄴ2/ → /ㄴ3/ → /ㅏ1/ → /ㅏ2/ → /ㅏ3/ → /ㄴ1&rsquo;/ → &hellip;</p>
<h2 id="방출-확률b_jo_t-상태-전이-확률a_ij">방출 확률($b_j(o_t)$), 상태 전이 확률($a_{ij}$)<a hidden class="anchor" aria-hidden="true" href="#방출-확률b_jo_t-상태-전이-확률a_ij">#</a></h2>
<p>그렇다면 대체 &lsquo;방출 확률($b_j(o_t)$)&lsquo;과 &lsquo;상태 전이 확률($a_{ij}$)&rsquo; 이라는 것은 어떻게 구할까?!</p>
<h3 id="상태-전이-확률a_ij-구하기">상태 전이 확률($a_{ij}$) 구하기<a hidden class="anchor" aria-hidden="true" href="#상태-전이-확률a_ij-구하기">#</a></h3>
<ol>
<li>전문가 지식 기반 초기화</li>
</ol>
<p>사용 시점: 모델 학습 시작 전 초기값 설정</p>
<ul>
<li>3-상태 left-to-right HMM 구조에서:</li>
<li>자기 루프(self-loop): $a_{ii} \approx 0.6$</li>
<li>다음 상태로 전이: $a_{i,i+1} \approx 0.4$
Kaldi의 topo 파일에 이러한 초기값 정의</li>
</ul>
<ol start="2">
<li>Baum-Welch 알고리즘 (EM 기반)</li>
</ol>
<p>사용 시점: 모델 학습 과정</p>
<ul>
<li>Baum-Welch 알고리즘 (EM 알고리즘의 HMM 버전)</li>
<li>E(Expectation)-단계: 전방($\alpha$)/후방($\beta$) 확률 계산</li>
<li>통계 수집: $\xi_t(i,j)$ (시간 $t$에 상태 $i$, 시간 $t+1$에 상태 $j$에 있을 확률)</li>
<li>M(Maximization)-단계: 상태 전이 확률 업데이트
$$a_{ij} = \frac{\sum_{t=1}^{T-1} \xi_t(i,j)}{\sum_{t=1}^{T-1} \gamma_t(i)}$$</li>
</ul>
<p>여기서:<br>
$\xi_t(i,j)$: 시간 $t$에 상태 $i$, 시간 $t+1$에 상태 $j$에 있을 확률<br>
$\gamma_t(i)$: 시간 $t$에 상태 $i$에 있을 확률</p>
<ol start="3">
<li>강제 정렬(Forced Alignment) 기반</li>
</ol>
<p>사용 시점: 모델 세련화 및 정제 단계</p>
<ul>
<li>음성-텍스트 쌍이 있는 학습 데이터 준비</li>
<li>현재 모델로 발화를 알려진 텍스트와 강제 정렬</li>
<li>상태 시퀀스를 카운트하여 전이 확률 계산(카운트를 정규화하여 확률 계산):
$$a_{ij} = \frac{카운트(상태 i에서 j로 전이)}{카운트(상태 i에서의 모든 전이)}$$</li>
</ul>
<h3 id="방출-확률b_jo_t-구하기">방출 확률($b_j(o_t)$) 구하기<a hidden class="anchor" aria-hidden="true" href="#방출-확률b_jo_t-구하기">#</a></h3>
<p>GMM은 여러 가우시안 분포의 가중 합으로 표현되는 확률 밀도 함수다. HMM-GMM 시스템에서는 각 HMM 상태의 방출 확률을 GMM으로 모델링한다:<br>
각 HMM 상태 $j$의 방출 확률은 가우시안 혼합 모델로 표현:<br>
$b_j(o_t) = \sum_{m=1}^M c_{jm} \mathcal{N}(o_t; \mu_{jm}, \Sigma_{jm})$<br></p>
<p>$c_{jm}$: $m$번째 가우시안 컴포넌트의 가중치 (모든 가중치 합은 1)<br>
$\mu_{jm}$: $m$번째 가우시안의 평균 벡터<br>
$\Sigma_{jm}$: $m$번째 가우시안의 공분산 행렬<br>
$\mathcal{N}(o_t; \mu, \Sigma)$: 평균 $\mu$, 공분산 $\Sigma$를 가진 다변량 가우시안 밀도 함수<br>
(나중에 따로 GMM에 대해서 포스팅을 하든지 해야겠다. 이 수식만 봐서는 어떻게 구할 수 있는 것인지 감이 안 잡힌다. 다만 아래 학습 과정으로 이루어 지는 것을 알고 넘어가자)</p>
<h4 id="방출-확률-학습방법">방출 확률 학습방법<a hidden class="anchor" aria-hidden="true" href="#방출-확률-학습방법">#</a></h4>
<ol>
<li>GMM 초기화</li>
</ol>
<p>사용 시점: 모델 학습 시작 전</p>
<p>방법:</p>
<ul>
<li>각 상태에 할당된 특징 벡터의 k-means 클러스터링</li>
<li>초기 GMM 컴포넌트 생성 (평균, 공분산, 가중치)</li>
<li>Kaldi에서는 gmm-init-mono 등의 명령어로 구현</li>
</ul>
<ol start="2">
<li>Baum-Welch 알고리즘 내 GMM 업데이트</li>
</ol>
<p>사용 시점: 모델 학습 과정</p>
<p>방법:</p>
<ul>
<li>E-단계에서 각 프레임의 상태 소속 확률 $\gamma_t(j)$ 계산</li>
<li>각 가우시안 컴포넌트에 대한 책임 확률($\gamma_t(j,m)$) 계산:
$$\gamma_t(j,m) = \gamma_t(j) \cdot \frac{c_{jm} \mathcal{N}(o_t; \mu_{jm}, \Sigma_{jm})}{\sum_{k=1}^M c_{jk} \mathcal{N}(o_t; \mu_{jk}, \Sigma_{jk})}$$
GMM 파라미터 업데이트:<br>
가중치: $c_{jm} = \frac{\sum_{t=1}^T \gamma_t(j,m)}{\sum_{t=1}^T \gamma_t(j)}$<br>
평균: $\mu_{jm} = \frac{\sum_{t=1}^T \gamma_t(j,m) \cdot o_t}{\sum_{t=1}^T \gamma_t(j,m)}$<br>
공분산: $\Sigma_{jm} = \frac{\sum_{t=1}^T \gamma_t(j,m) \cdot (o_t - \mu_{jm})(o_t - \mu_{jm})^T}{\sum_{t=1}^T \gamma_t(j,m)}$<br></li>
</ul>
<ol start="3">
<li>정렬 기반 GMM 세련화</li>
</ol>
<p>사용 시점: 모델 세련화 단계</p>
<p>방법:</p>
<ul>
<li>강제 정렬로 특징 벡터를 HMM 상태에 할당</li>
<li>정렬된 데이터로 더 복잡한 GMM 학습 (예: 혼합 수 증가)</li>
<li>Kaldi에서는 gmm-acc-stats-ali와 gmm-est로 구현</li>
</ul>
<h4 id="책임-확률-수식">책임 확률 수식<a hidden class="anchor" aria-hidden="true" href="#책임-확률-수식">#</a></h4>
<p>$$\gamma_t(j,m) = \gamma_t(j) \cdot \frac{c_{jm} \mathcal{N}(o_t; \mu_{jm}, \Sigma_{jm})}{\sum_{k=1}^M c_{jk} \mathcal{N}(o_t; \mu_{jk}, \Sigma_{jk})}$$
이 수식은 상태 $j$의 $m$번째 가우시안 컴포넌트가 관측값 $o_t$를 생성할 책임(responsibility) 을 나타낸다. 즉, 관측값 $o_t$가 상태 $j$에서 생성되었다는 조건하에, 그 중에서도 $m$번째 가우시안 컴포넌트에서 생성되었을 확률이다.</p>
<h4 id="방출-확률-수식">방출 확률 수식<a hidden class="anchor" aria-hidden="true" href="#방출-확률-수식">#</a></h4>
<p>$$b_j(o_t) = \sum_{m=1}^M c_{jm} \mathcal{N}(o_t; \mu_{jm}, \Sigma_{jm})$$
이 수식은 상태 $j$에서 관측값 $o_t$를 생성할 방출 확률(emission probability) 을 나타낸다. GMM으로 모델링된 확률 밀도 함수이다.<br></p>
<h4 id="두-수식의-관계">두 수식의 관계<a hidden class="anchor" aria-hidden="true" href="#두-수식의-관계">#</a></h4>
<p>중요한 점은 첫 번째 수식의 분모가 바로 두 번째 수식과 같다는 것이다:<br>
$$\sum_{k=1}^M c_{jk} \mathcal{N}(o_t; \mu_{jk}, \Sigma_{jk}) = b_j(o_t)$$
따라서 첫 번째 수식은 다음과 같이 다시 쓸 수 있다:<br></p>
<p>$$\gamma_t(j,m) = \gamma_t(j) \cdot \frac{c_{jm} \mathcal{N}(o_t; \mu_{jm}, \Sigma_{jm})}{b_j(o_t)}$$
이는 Baum-Welch 알고리즘의 E-단계에서 계산되는 값으로:<br>
$\gamma_t(j)$: 시간 $t$에 상태 $j$에 있을 확률<br>
$\frac{c_{jm} \mathcal{N}(o_t; \mu_{jm}, \Sigma_{jm})}{b_j(o_t)}$: 상태 $j$ 내에서 $m$번째 가우시안 컴포넌트의 기여도
두 수식은 다른 의미를 가지지만, GMM 파라미터 학습 과정에서 서로 연관되어 사용된다:</p>
<ol>
<li>방출 확률 $b_j(o_t)$는 HMM의 기본 구성요소</li>
<li>책임 확률 $\gamma_t(j,m)$은 GMM 파라미터 업데이트에 사용되는 통계량</li>
</ol>
<h2 id="dnn-hmm-하이브리드-시스템에서-dnn의-gmm-대체-방식">DNN-HMM 하이브리드 시스템에서 DNN의 GMM 대체 방식<a hidden class="anchor" aria-hidden="true" href="#dnn-hmm-하이브리드-시스템에서-dnn의-gmm-대체-방식">#</a></h2>
<h3 id="기본-개념의-변화">기본 개념의 변화<a hidden class="anchor" aria-hidden="true" href="#기본-개념의-변화">#</a></h3>
<p>GMM-HMM 시스템에서 DNN-HMM 하이브리드 시스템으로의 전환은 ASR 발전에 있어 중요한 패러다임 변화였다. 주요 변화는 다음과 같다</p>
<p>GMM-HMM에서</p>
<ul>
<li>GMM은 생성 모델(generative model)로 $p(o_t|s_j)$, 즉 상태 $j$가 주어졌을 때 관측값 $o_t$의 우도(likelihood)를 직접 모델링<br></li>
<li>각 HMM 상태마다 별도의 GMM이 존재<br></li>
<li>방출 확률: $b_j(o_t) = p(o_t|s_j) = \sum_{m=1}^M c_{jm} \mathcal{N}(o_t; \mu_{jm}, \Sigma_{jm})$<br>
DNN-HMM에서:<br></li>
<li>DNN은 판별 모델(discriminative model)로 $p(s_j|o_t)$, 즉 관측값 $o_t$가 주어졌을 때 상태 $j$의 사후 확률(posterior)을 예측<br></li>
<li>하나의 DNN이 모든 상태의 사후 확률을 동시에 출력<br></li>
<li>베이즈 규칙으로 우도로 변환: $p(o_t|s_j) \propto \frac{p(s_j|o_t)}{p(s_j)}$<br></li>
</ul>
<h3 id="dnn이-gmm을-대체하는-메커니즘">DNN이 GMM을 대체하는 메커니즘<a hidden class="anchor" aria-hidden="true" href="#dnn이-gmm을-대체하는-메커니즘">#</a></h3>
<p>DNN은 다음과 같은 방식으로 GMM의 역할을 대체한다:<br>
입력: 음향 특징(MFCC, FBANK 등)과 그 문맥(앞뒤 프레임)<br>
출력: 각 HMM 상태(senone)에 대한 사후 확률<br>
디코딩 시 사용: 베이즈 규칙을 통해 우도로 변환<br></p>
<h4 id="gmm-hmm으로-초기-강제-정렬-수행">GMM-HMM으로 초기 강제 정렬 수행<a hidden class="anchor" aria-hidden="true" href="#gmm-hmm으로-초기-강제-정렬-수행">#</a></h4>
<p>정렬된 프레임 레이블을 사용해 DNN 학습 (교차 엔트로피 손실 함수)<br>
출력층은 softmax 활성화 함수를 통해 모든 HMM 상태에 대한 확률 출력<br></p>
<h4 id="디코딩-단계">디코딩 단계<a hidden class="anchor" aria-hidden="true" href="#디코딩-단계">#</a></h4>
<p>DNN이 각 프레임에 대한 상태 사후 확률 $p(s_j|o_t)$ 출력<br>
사후 확률을 우도로 변환: $p(o_t|s_j) \propto \frac{p(s_j|o_t)}{p(s_j)}$<br>
이 우도를 HMM 디코더에 제공 (Viterbi, Beam Search 등)<br>
여기서 $p(s_j)$는 상태의 사전 확률로, 학습 데이터에서 각 상태의 출현 빈도를 계산하여 얻는다.</p>
<h3 id="주요-혁신-포인트">주요 혁신 포인트<a hidden class="anchor" aria-hidden="true" href="#주요-혁신-포인트">#</a></h3>
<ol>
<li>특징 표현력</li>
</ol>
<p>GMM: 확률 분포를 명시적으로 모델링하지만 복잡한 패턴 인식에 제한적<br>
DNN: 비선형 변환을 통해 더 복잡한 패턴 인식 가능, 더 강력한 특징 표현 학습<br></p>
<ol start="2">
<li>문맥 정보 활용</li>
</ol>
<p>GMM: 주로 현재 프레임의 특징만 사용<br>
DNN: 여러 프레임을 입력으로 받아 더 긴 문맥 정보 활용 가능 (예: 9프레임 윈도우)<br></p>
<ol start="3">
<li>파라미터 공유</li>
</ol>
<p>GMM: 각 상태마다 별도의 파라미터 집합<br>
DNN: 하나의 네트워크로 모든 상태의 확률 계산, 하위 층에서 특징 표현 공유<br></p>


        </div>
        <div class="post-reward">
            <div style="padding: 0 0 0 0; margin: 0 0 0 0; width: 100%; font-size:16px; text-align: center;">
                <div id="QR" style="opacity: 0;">
                    <div id="wechat" style="display: inline-block">
                        <a class="fancybox" rel="group">
                            <img id="wechat_qr" src="http://localhost:1313/img/wechat_pay.png" alt="wechat_pay"></a>
                        <p>微信</p>
                    </div>
                    <div id="alipay" style="display: inline-block">
                        <a class="fancybox" rel="group">
                            <img id="alipay_qr" src="http://localhost:1313/img/alipay.png" alt="alipay"></a>
                        <p>支付宝</p>
                    </div>
                </div>
                
            </div>
        </div>

        <footer class="post-footer">
            
<nav class="paginav">
  <a class="prev" href="http://localhost:1313/posts/tech/asr/beam_search/">
    <span class="title">« 이전 페이지</span>
    <br>
    <span>Beam Search</span>
  </a>
  <a class="next" href="http://localhost:1313/posts/tech/linear_algebra/eigenvalues_eigenvectors/">
    <span class="title">다음 페이지 »</span>
    <br>
    <span>Eigenvalues &amp; Eigenvectors</span>
  </a>
</nav>

        </footer>
    </div>

<div id="disqus_thread"></div>
<script>
    

    

    (function() { 
    var d = document, s = d.createElement('script');
    s.src = 'https://basic-18.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

<style>
    .comments_details summary::marker {
        font-size: 20px;
        content: '👉展开评论';
        color: var(--content);
    }
    .comments_details[open] summary::marker{
        font-size: 20px;
        content: '👇关闭评论';
        color: var(--content);
    }
</style>


<div>
    <details class="comments_details">
        <summary style="cursor: pointer; margin: 50px 0 20px 0;width: 130px;">
            <span style="font-size: 20px;color: var(--content);">...</span>
        </summary>
        <div id="tcomment"></div>
    </details>
    <script src="https://cdn.staticfile.org/twikoo/1.5.8/twikoo.all.min.js">
    </script>
    <script>
        twikoo.init({
            envId:  null ,
        el: "#tcomment",
            lang: 'en-US',
            region:  null ,
        path: window.TWIKOO_MAGIC_PATH||window.location.pathname,
        })
    </script>
</div>

</article>
</main>

<footer class="footer">
    <span>
        Copyright
        &copy;
        2020-2025
        <a href="http://localhost:1313/" style="color:#939393;">macsim&#39;s Blog</a>
        All Rights Reserved
    </span>
    <a href="https://beian.miit.gov.cn/" target="_blank" style="color:#939393;"></a>&nbsp;
    <span>
        <a target="_blank" href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=null"
           style="display:inline-block;text-decoration:none;height:20px;color:#939393;">
            <img src="" style="float:left;margin: 0px 5px 0px 0px;"/>
            
        </a>
    </span>
    <span id="busuanzi_container">
        <span class="fa fa-user"></span> <span id="busuanzi_value_site_uv"></span>
        <span class="fa fa-eye"></span> <span id="busuanzi_value_site_pv"></span>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <span class="topInner">
        <svg class="topSvg" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
            <path d="M12 6H0l6-6z"/>
        </svg>
        <span id="read_progress"></span>
    </span>
</a>

<script>
    document.addEventListener('scroll', function (e) {
        const readProgress = document.getElementById("read_progress");
        const scrollHeight = document.documentElement.scrollHeight;
        const clientHeight = document.documentElement.clientHeight;
        const scrollTop = document.documentElement.scrollTop || document.body.scrollTop;
        readProgress.innerText = ((scrollTop / (scrollHeight - clientHeight)).toFixed(2) * 100).toFixed(0);
    })
</script>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });
</script>
<script>
    let mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 200 || document.documentElement.scrollTop > 200) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };
</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        (function() {
            document.cookie = "change-themes" + "="+ escape ("false");
        })()

        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    });
</script>

<script>
    document.body.addEventListener('copy', function (e) {
        if (window.getSelection().toString() && window.getSelection().toString().length > 50) {
            let clipboardData = e.clipboardData || window.clipboardData;
            if (clipboardData) {
                e.preventDefault();
                let htmlData = window.getSelection().toString() +
                    '\r\n\n————————————————\r\n' +
                    '版权声明：本文为「'+"macsim's Blog"+'」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。' +
                '\r\n原文链接：' + location.href;
                let textData = window.getSelection().toString() +
                    '\r\n\n————————————————\r\n' +
                    '版权声明：本文为「'+"macsim's Blog"+'」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。' +
                '\r\n原文链接：' + location.href;
                clipboardData.setData('text/html', htmlData);
                clipboardData.setData('text/plain', textData);
            }
        }
    });
</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;
        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = '복사';

        function copyingDone() {
            copybutton.innerText = '복사 완료!';
            setTimeout(() => {
                copybutton.innerText = '복사';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                let text = codeblock.textContent +
                    '\r\n————————————————\r\n' +
                    '版权声明：本文为「'+"macsim's Blog"+'」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。' +
                '\r\n原文链接：' + location.href;
                navigator.clipboard.writeText(text);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) {}
            selection.removeRange(range);
        });

        let language = codeblock.className.replaceAll("language-", "")
        let macTool = document.createElement("div")
        let macTool1 = document.createElement("div")
        let macTool2 = document.createElement("div")
        let macTool3 = document.createElement("div")
        let languageType = document.createElement("div")
        languageType.innerText = language
        macTool.setAttribute('class', 'mac-tool')
        macTool1.setAttribute('class', 'mac bb1')
        macTool2.setAttribute('class', 'mac bb2')
        macTool3.setAttribute('class', 'mac bb3')
        languageType.setAttribute('class', 'language-type')
        macTool.appendChild(macTool1)
        macTool.appendChild(macTool2)
        macTool.appendChild(macTool3)
        macTool.appendChild(languageType)

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
            container.appendChild(macTool)
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
            container.appendChild(macTool)
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
            container.appendChild(macTool)
        }
    });
</script>
</body>

</html>
